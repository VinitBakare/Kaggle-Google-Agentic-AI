{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Submission for Kaggle Google Agentic AI course held from 10th to 15th November 2025.\n",
        "\n",
        "* Gemini API key setup ** [link text](https://ai.google.dev/gemini-api/docs/api-key)\n",
        "\n",
        "* Kaggle API steup ** [link text](https://www.kaggle.com/docs/api)"
      ],
      "metadata": {
        "id": "DQfCttsXwVVV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "617d2551"
      },
      "source": [
        "## Overall Implementation Plan\n",
        "\n",
        "This notebook is designed to automate and streamline data analysis, from raw data ingestion to a comprehensive final report, using a multi-agent system orchestrated by LangGraph. The pipeline integrates various components including environment setup, data ingestion, guardrails, analytical agents, Large Language Model (LLM) integration, human-in-the-loop checkpoints, and report generation.\n",
        "\n",
        "### 1. Environment Setup\n",
        "\n",
        "*   **Initial Setup**: The first step involves installing necessary Python libraries (`google-generativeai`, `langchain`, `langgraph`, `redis`, `pandas`, `numpy`, `plotly`, `python-docx`, `pypdf`, `kaleido`) and `graphviz` for graph visualization. Essential modules like `os`, `re`, `json`, `datetime`, `logging`, `typing`, `pandas`, `numpy`, `plotly`, and `docx` are imported.\n",
        "*   **Gemini API Configuration**: The Google Gemini API key is securely retrieved from Colab's secrets manager and configured for use with `google.generativeai`.\n",
        "*   **Redis Integration**: A Redis server is installed and started to serve as a fast, persistent cache. The Python `redis` client is then installed and initialized, with a fallback to an in-memory dictionary if Redis is unavailable.\n",
        "\n",
        "### 2. Data Ingestion\n",
        "\n",
        "*   **File Loading**: The `node_ingestion` function in the LangGraph pipeline is responsible for reading various file types provided by the user. It distinguishes between:\n",
        "    *   **Tabular Files**: `.csv`, `.txt`, `.xls`, `.xlsx` files are loaded into pandas DataFrames using `pd.read_csv` or `pd.read_excel`.\n",
        "    *   **Textual Files**: `.pdf`, `.docx`, `.md`, `.txt` files are parsed to extract raw text content using libraries like `pypdf` and `python-docx`. Raw file bytes are wrapped in `BytesIO` objects for file-like processing.\n",
        "\n",
        "### 3. Guardrails\n",
        "\n",
        "*   **PII Detection**: The `node_guardrails_input` function scans both DataFrames (column names, object-type column values) and raw text for Personally Identifiable Information (PII) using predefined regular expressions for emails and phone numbers.\n",
        "*   **Data Sanitization**: If PII is detected, the system automatically sanitizes the data by renaming columns (e.g., `_MASKED`) and replacing actual PII values with `[MASKED]` to prevent sensitive information from being processed further or included in the final report.\n",
        "*   **Output Guardrails**: The `node_guardrails_output` re-scans the final narrative for PII-like patterns before report generation, masking any detected instances to ensure the final output is compliant.\n",
        "\n",
        "### 4. Analytical Agents\n",
        "\n",
        "*   **Exploratory Data Analysis (EDA)**:\n",
        "    *   **Purpose**: The `node_eda` function performs initial descriptive statistics on the primary DataFrame. It calculates summary statistics (`df.describe`), identifies missing values (`df.isnull().sum()`), and computes correlation matrices for numeric columns (`df.corr().abs()`).\n",
        "    *   **Output**: Provides a concise summary of the DataFrame's shape, missing data, and highlights from descriptive statistics.\n",
        "*   **Data Science Analysis**:\n",
        "    *   **Purpose**: The `node_data_science` function delves deeper into the data. It identifies highly correlated numeric column pairs, computes grouped aggregates for categorical features, detects and analyzes time-series trends, and builds a simple linear regression model if sufficient numeric columns are present.\n",
        "    *   **Output**: Summarizes key insights from correlations, group-by operations, time trends, and the performance of the regression model (R-squared, MAE).\n",
        "*   **Plotting**:\n",
        "    *   **Purpose**: The `node_plotting` function generates various visualizations using `matplotlib.pyplot` to visually represent key data characteristics.\n",
        "    *   **Output**: Produces and saves several types of plots, including distribution histograms for numeric columns, time-series trends (if a date column exists), and bar plots for categorical-numeric relationships. Each plot is saved as a PNG with a unique filename and a descriptive caption.\n",
        "\n",
        "### 5. LLM Integration\n",
        "\n",
        "*   **Data Analyst Agent**:\n",
        "    *   **Purpose**: The `node_data_analyst` uses a Gemini LLM (`gemini-2.5-pro`) to synthesize the EDA results, data science findings, and plot descriptions into a clear, non-technical narrative.\n",
        "    *   **Workflow**: It constructs a prompt with all relevant context and the user's goal, then generates an initial draft of the analysis report.\n",
        "*   **LLM Judge Agent**:\n",
        "    *   **Purpose**: The `node_llm_judge` acts as a critical reviewer. It evaluates the analyst's draft narrative for coherence, completeness, and accuracy against the raw analytical results.\n",
        "    *   **Workflow**: It takes the draft narrative and all analytical context, generates a revised, improved narrative, and provides evaluation notes detailing the improvements or confirming the original's completeness.\n",
        "\n",
        "### 6. Human-in-the-Loop Checkpoints\n",
        "\n",
        "*   **Post-EDA Checkpoint (`node_user_checkpoint_1`)**: After the initial EDA, the pipeline pauses to allow the user to provide a specific `user_focus`. This input can guide subsequent data science analysis.\n",
        "*   **Pre-Report Checkpoint (`node_user_checkpoint_2`)**: Before the final report generation, the user is presented with the judge-refined narrative and can provide additional requests or modifications, ensuring human oversight and customization.\n",
        "\n",
        "### 7. Report Generation\n",
        "\n",
        "*   **Word Report Creation**: The `node_report_generation` function generates a professional Word document (`.docx`) using the `python-docx` library. It incorporates the final, human-reviewed narrative, formatted with appropriate headings and bullet points.\n",
        "*   **Plot Embedding**: All generated plots are embedded into the Word document with their respective captions, providing a visual complement to the textual analysis.\n",
        "\n",
        "### LangGraph Orchestration\n",
        "\n",
        "*   The entire process is orchestrated by a `StateGraph` from `langgraph`. Each step described above is implemented as a `node` within this graph.\n",
        "*   `Edges` define the flow between these nodes, creating a sequential pipeline. The `PipelineState` dataclass holds all intermediate and final results, ensuring data is consistently passed between agents.\n",
        "*   The `run_pipeline` function initializes the Gemini model, sets up the initial `PipelineState` with the user's goal and uploaded data, builds the graph, compiles it, and invokes the execution, managing the flow through all the defined agents and checkpoints.\n",
        "\n",
        "This robust architecture ensures a comprehensive, intelligent, and flexible data analysis workflow with built-in quality checks and human intervention points.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76a648a0"
      },
      "source": [
        "### 1. Install Redis Server\n",
        "\n",
        "First, we'll install the `redis-server` package using `apt-get`. This will set up the Redis server on the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7476c259",
        "outputId": "82add6ec-3c5a-4e27-fef3-91dd535bcfda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Waiting for headers] [C\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,153 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,836 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,008 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,491 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,592 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,535 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,870 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,222 kB]\n",
            "Get:22 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Fetched 37.5 MB in 6s (6,697 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libjemalloc2 liblua5.1-0 liblzf1 lua-bitop lua-cjson redis-tools\n",
            "Suggested packages:\n",
            "  ruby-redis\n",
            "The following NEW packages will be installed:\n",
            "  libjemalloc2 liblua5.1-0 liblzf1 lua-bitop lua-cjson redis-server\n",
            "  redis-tools\n",
            "0 upgraded, 7 newly installed, 0 to remove and 57 not upgraded.\n",
            "Need to get 1,273 kB of archives.\n",
            "After this operation, 5,725 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjemalloc2 amd64 5.2.1-4ubuntu1 [240 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblua5.1-0 amd64 5.1.5-8.1build4 [99.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblzf1 amd64 3.6-3 [7,444 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lua-bitop amd64 1.0.2-5 [6,680 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lua-cjson amd64 2.1.0+dfsg-2.1 [17.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 redis-tools amd64 5:6.0.16-1ubuntu1.1 [856 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 redis-server amd64 5:6.0.16-1ubuntu1.1 [45.9 kB]\n",
            "Fetched 1,273 kB in 1s (1,024 kB/s)\n",
            "Selecting previously unselected package libjemalloc2:amd64.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libjemalloc2_5.2.1-4ubuntu1_amd64.deb ...\n",
            "Unpacking libjemalloc2:amd64 (5.2.1-4ubuntu1) ...\n",
            "Selecting previously unselected package liblua5.1-0:amd64.\n",
            "Preparing to unpack .../1-liblua5.1-0_5.1.5-8.1build4_amd64.deb ...\n",
            "Unpacking liblua5.1-0:amd64 (5.1.5-8.1build4) ...\n",
            "Selecting previously unselected package liblzf1:amd64.\n",
            "Preparing to unpack .../2-liblzf1_3.6-3_amd64.deb ...\n",
            "Unpacking liblzf1:amd64 (3.6-3) ...\n",
            "Selecting previously unselected package lua-bitop:amd64.\n",
            "Preparing to unpack .../3-lua-bitop_1.0.2-5_amd64.deb ...\n",
            "Unpacking lua-bitop:amd64 (1.0.2-5) ...\n",
            "Selecting previously unselected package lua-cjson:amd64.\n",
            "Preparing to unpack .../4-lua-cjson_2.1.0+dfsg-2.1_amd64.deb ...\n",
            "Unpacking lua-cjson:amd64 (2.1.0+dfsg-2.1) ...\n",
            "Selecting previously unselected package redis-tools.\n",
            "Preparing to unpack .../5-redis-tools_5%3a6.0.16-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking redis-tools (5:6.0.16-1ubuntu1.1) ...\n",
            "Selecting previously unselected package redis-server.\n",
            "Preparing to unpack .../6-redis-server_5%3a6.0.16-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking redis-server (5:6.0.16-1ubuntu1.1) ...\n",
            "Setting up libjemalloc2:amd64 (5.2.1-4ubuntu1) ...\n",
            "Setting up lua-cjson:amd64 (2.1.0+dfsg-2.1) ...\n",
            "Setting up liblzf1:amd64 (3.6-3) ...\n",
            "Setting up lua-bitop:amd64 (1.0.2-5) ...\n",
            "Setting up liblua5.1-0:amd64 (5.1.5-8.1build4) ...\n",
            "Setting up redis-tools (5:6.0.16-1ubuntu1.1) ...\n",
            "Setting up redis-server (5:6.0.16-1ubuntu1.1) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Created symlink /etc/systemd/system/redis.service → /lib/systemd/system/redis-server.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/redis-server.service → /lib/systemd/system/redis-server.service.\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install redis-server -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c53bd40e"
      },
      "source": [
        "### 2. Start Redis Server\n",
        "\n",
        "Next, we'll start the Redis server in the background. The `&` at the end makes it run as a background process, allowing the notebook to continue executing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee73b90a"
      },
      "source": [
        "This cell executes the shell command `!redis-server --daemonize yes`.\n",
        "\n",
        "This command starts the Redis server as a background process (`--daemonize yes`). Running it in daemonize mode means Redis will run independently of the current terminal session, allowing subsequent commands to be executed without waiting for Redis to finish. The cell itself produces no standard output or error, indicating that the command was successfully issued."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c04e951b"
      },
      "outputs": [],
      "source": [
        "!redis-server --daemonize yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "392394ee"
      },
      "source": [
        "### 3. Install Redis Python Client\n",
        "\n",
        "To interact with the Redis server from Python, we need to install the `redis` client library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6449f2f7",
        "outputId": "20d88924-65aa-45d6-97ea-99daf56a6bae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting redis\n",
            "  Downloading redis-7.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading redis-7.1.0-py3-none-any.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.2/354.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: redis\n",
            "Successfully installed redis-7.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install redis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpxiG6DCswJP"
      },
      "source": [
        "### connect and test Redis\n",
        "\n",
        "This cell contains Python code to connect to and test the Redis server:\n",
        "\n",
        "1.  `import redis`: Imports the Redis Python client library.\n",
        "2.  `r = redis.Redis(host='localhost', port=6379, db=0)`: Creates an instance of the Redis client, connecting to the Redis server running locally on port 6379, using database 0.\n",
        "3.  `print(f\"Redis PING: {r.ping()}\")`: Sends a `PING` command to the Redis server. If the server is alive and reachable, it returns `True`. The output confirms `Redis PING: True`.\n",
        "4.  `r.set('colab-test-key', 'Hello from Colab Redis!')`: Sets a key-value pair in Redis. The key is `'colab-test-key'` and the value is `'Hello from Colab Redis!'`. The output confirms `Set 'colab-test-key' to 'Hello from Colab Redis!'`.\n",
        "5.  `value = r.get('colab-test-key')`: Retrieves the value associated with `'colab-test-key'`. Redis stores values as bytes, so `.decode('utf-8')` is used to convert it to a human-readable string. The output shows `Get 'colab-test-key': Hello from Colab Redis!`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c7f27cd",
        "outputId": "a84f8ac8-1bf7-4ed2-fbf3-68e644787edf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Redis PING: True\n",
            "Set 'colab-test-key' to 'Hello from Colab Redis!'\n",
            "Get 'colab-test-key': Hello from Colab Redis!\n"
          ]
        }
      ],
      "source": [
        "import redis\n",
        "\n",
        "r = redis.Redis(host='localhost', port=6379, db=0)\n",
        "\n",
        "# Test connection\n",
        "print(f\"Redis PING: {r.ping()}\")\n",
        "\n",
        "# Set a key-value pair\n",
        "r.set('colab-test-key', 'Hello from Colab Redis!')\n",
        "print(\"Set 'colab-test-key' to 'Hello from Colab Redis!'\")\n",
        "\n",
        "# Get the value\n",
        "value = r.get('colab-test-key')\n",
        "print(f\"Get 'colab-test-key': {value.decode('utf-8')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0a5c236"
      },
      "source": [
        "This cell performs initial environment setup:\n",
        "\n",
        "1.  `!pip install -q ...`: Installs several Python libraries quietly (`-q` flag). These libraries include `google-generativeai`, `langchain`, `langgraph`, `redis`, `pandas`, `numpy`, `plotly`, `python-docx`, `pypdf`, and `kaleido`. The output confirms the successful installation of these packages.\n",
        "2.  `import os`, `import re`, `import json`, etc.: Imports necessary Python modules for various functionalities later in the notebook.\n",
        "3.  `os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\", \"YOUR_GEMINI_API_KEY_HERE\")`: This line attempts to set the `GOOGLE_API_KEY` environment variable. It first tries to get the value from an existing environment variable named `GOOGLE_API_KEY`, and if not found, it defaults to the placeholder `\"YOUR_GEMINI_API_KEY_HERE\"`. This is important for authenticating with Google's generative AI services."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "479fdd69",
        "outputId": "5a028aba-b8e5-4faf-c04f-cf057bf5cca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.1/236.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Cell 1: Environment setup\n",
        "# Install required packages\n",
        "!pip install -q google-generativeai langchain langgraph redis pandas numpy 'plotly>=6.1.1' python-docx pypdf python-docx==1.0.0 kaleido\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import uuid\n",
        "import datetime\n",
        "import logging\n",
        "from typing import Dict, List, Optional, Any, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "\n",
        "# Gemini API setup (replace with your actual key or load via .env)\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\", \"YOUR_GEMINI_API_KEY_HERE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoP88ROLsAzd"
      },
      "source": [
        "This cell further configures the Google Gemini API:\n",
        "\n",
        "1.  `import google.generativeai as genai` and `from google.colab import userdata`: Imports the Gemini API client and Colab's `userdata` module, which is used to securely access secrets.\n",
        "2.  `api_key_from_secrets = userdata.get(\"GOOGLE_API_KEY\")`: Retrieves the `GOOGLE_API_KEY` from Colab's secrets manager. This is a secure way to handle API keys without hardcoding them directly into the notebook.\n",
        "3.  `os.environ[\"GOOGLE_API_KEY\"] = api_key_from_secrets`: Sets the retrieved API key as an environment variable, making it accessible to other parts of the code that might read from environment variables.\n",
        "4.  `genai.configure(api_key=api_key_from_secrets)`: Configures the Gemini API client with the obtained API key, authenticating subsequent calls to Gemini services."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64d7e78f"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Gemini API setup: retrieve the API key from Colab's secrets manager\n",
        "# Ensure your secret is named 'GOOGLE_API_KEY' in Colab.\n",
        "api_key_from_secrets = userdata.get(\"GOOGLE_API_KEY\")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key_from_secrets # Set it in environment for load_env_var\n",
        "genai.configure(api_key=api_key_from_secrets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-dsgbjurs0a"
      },
      "source": [
        "### Explanation of config & utility\n",
        "\n",
        "This cell defines configuration and utility functions:\n",
        "\n",
        "1.  `class PipelineError(Exception):`: Defines a custom exception class for pipeline-related errors.\n",
        "2.  `def load_env_var(name: str, default: Optional[str] = None) -> str:`: A utility function to load environment variables. It raises a `PipelineError` if a required environment variable is not set and no default is provided.\n",
        "3.  `def log(message: str, level: str = \"INFO\") -> None:`: A simple logging function to standardize output messages with a timestamp and level.\n",
        "4.  **Redis Initialization**: This block attempts to initialize a Redis client.\n",
        "    *   `import redis` and `redis_client = redis.Redis(...)`: Imports the `redis` library and tries to connect to the Redis server on `localhost:6379`.\n",
        "    *   `redis_client.ping()`: Tests the connection to Redis. If successful, `USE_REDIS` is set to `True`, and an empty dictionary `CACHE` is initialized as a fallback (though `USE_REDIS` will govern if Redis is actually used). Since Redis was successfully started in a previous cell, this connection should succeed.\n",
        "    *   If Redis connection fails for any reason, a warning is logged, `USE_REDIS` is set to `False`, and `CACHE` becomes the primary in-memory cache."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dm2Fb7E12Y1v"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Config & utilities\n",
        "\n",
        "class PipelineError(Exception):\n",
        "    \"\"\"Custom exception for pipeline errors.\"\"\"\n",
        "    pass\n",
        "\n",
        "def load_env_var(name: str, default: Optional[str] = None) -> str:\n",
        "    \"\"\"Load environment variables with an optional default.\"\"\"\n",
        "    value = os.getenv(name, default)\n",
        "    if not value:\n",
        "        raise PipelineError(f\"Environment variable '{name}' is not set.\")\n",
        "    return value\n",
        "\n",
        "def log(message: str, level: str = \"INFO\") -> None:\n",
        "    \"\"\"Simple logger to standardize output.\"\"\"\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] [{level}] {message}\")\n",
        "\n",
        "# Redis initialization with fallback\n",
        "try:\n",
        "    import redis\n",
        "    redis_client = redis.Redis(host=\"localhost\", port=6379, db=0)\n",
        "    # test connection\n",
        "    redis_client.ping()\n",
        "    CACHE: Dict[str, Any] = {}  # fallback dict if Redis breaks later\n",
        "    USE_REDIS = True\n",
        "except Exception as e:\n",
        "    log(\"Redis not available, falling back to in-memory cache.\", \"WARNING\")\n",
        "    USE_REDIS = False\n",
        "    CACHE: Dict[str, Any] = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvpflev_rUNG"
      },
      "source": [
        "### Explanation of data ingestion and file parsing\n",
        "\n",
        "This cell defines functions for data ingestion and file parsing:\n",
        "\n",
        "1.  `from io import BytesIO` and `import pypdf`, `import docx`: Imports necessary libraries for handling byte streams and parsing PDF/DOCX files.\n",
        "2.  `def load_tabular_files(upload_dir_or_files: Dict[str, bytes]) -> Dict[str, pd.DataFrame]:`: This function takes a dictionary of filenames and their byte content. It iterates through the files, checks their extensions (`.csv`, `.txt`, `.xls`, `.xlsx`), and attempts to load them into pandas DataFrames. It uses `pd.read_csv` or `pd.read_excel` depending on the file type.\n",
        "3.  `def load_textual_files(upload_dir_or_files: Dict[str, bytes]) -> Dict[str, str]:`: This function similarly takes filenames and byte content, but focuses on text-based files (`.pdf`, `.docx`, `.md`, `.txt`). It uses `pypdf` for PDFs, `python-docx` for DOCX files, and direct decoding for Markdown and TXT files to extract their text content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIedGsNJ2i_S"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Data ingestion & file parsing\n",
        "\n",
        "from io import BytesIO\n",
        "import pypdf\n",
        "import docx\n",
        "\n",
        "def load_tabular_files(upload_dir_or_files: Dict[str, bytes]) -> Dict[str, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Load CSV and Excel files into pandas DataFrames.\n",
        "    Args:\n",
        "        upload_dir_or_files: a dict mapping filenames (str) to file contents (bytes).\n",
        "    Returns:\n",
        "        dict of filename -> DataFrame\n",
        "    \"\"\"\n",
        "    dfs = {}\n",
        "    for filename_key, file_content_bytes in upload_dir_or_files.items():\n",
        "        # Ensure filename is a string, decode if it's bytes (robustness)\n",
        "        filename = filename_key.decode('utf-8') if isinstance(filename_key, bytes) else filename_key\n",
        "        try:\n",
        "            # Wrap bytes in BytesIO for explicit file-like object handling\n",
        "            file_obj = BytesIO(file_content_bytes)\n",
        "            if filename.lower().endswith(tuple([\".csv\", \".txt\"])): # Explicit tuple for endswith\n",
        "                df = pd.read_csv(file_obj)\n",
        "            elif filename.lower().endswith(tuple([\".xls\", \".xlsx\"])): # Explicit tuple for endswith\n",
        "                df = pd.read_excel(file_obj)\n",
        "            else:\n",
        "                continue\n",
        "            dfs[filename] = df\n",
        "        except Exception as e:\n",
        "            log(f\"Failed to load {filename}: {e}\", \"ERROR\")\n",
        "    return dfs\n",
        "\n",
        "def load_textual_files(upload_dir_or_files: Dict[str, bytes]) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Load PDF, DOCX, Markdown, and TXT files into raw text.\n",
        "    Args:\n",
        "        upload_dir_or_files: dict mapping filenames (str) to file contents (bytes).\n",
        "    Returns:\n",
        "        dict of filename -> extracted text\n",
        "    \"\"\"\n",
        "    texts = {}\n",
        "    for filename_key, file_content_bytes in upload_dir_or_files.items():\n",
        "        # Ensure filename is a string, decode if it's bytes (robustness)\n",
        "        filename = filename_key.decode('utf-8') if isinstance(filename_key, bytes) else filename_key\n",
        "        try:\n",
        "            # Wrap bytes in BytesIO for pypdf and docx\n",
        "            file_obj = BytesIO(file_content_bytes)\n",
        "            if filename.lower().endswith(\".pdf\"):\n",
        "                reader = pypdf.PdfReader(file_obj)\n",
        "                text = \"\".join([page.extract_text() or \"\" for page in reader.pages])\n",
        "            elif filename.lower().endswith(\".docx\"):\n",
        "                doc = docx.Document(file_obj)\n",
        "                text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "            elif filename.lower().endswith(tuple([\".md\", \".txt\"])): # Explicit tuple for endswith\n",
        "                text = file_content_bytes.decode(\"utf-8\") # Can decode directly for these\n",
        "            else:\n",
        "                continue\n",
        "            texts[filename] = text\n",
        "        except Exception as e:\n",
        "            log(f\"Failed to parse {filename}: {e}\", \"ERROR\")\n",
        "    return texts\n",
        "\n",
        "# Demo stub: illustrate how to use this with Colab's file upload\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# dfs = load_tabular_files(uploaded)\n",
        "# texts = load_textual_files(uploaded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I3Lsy1XrApu"
      },
      "source": [
        "### Explanation of Guardrails\n",
        "\n",
        "This cell implements guardrails for identifying and sanitizing Personally Identifiable Information (PII):\n",
        "\n",
        "1.  `PII_PATTERNS`: A dictionary defining regular expressions for common PII patterns like email addresses and phone numbers. This allows the system to detect potentially sensitive information.\n",
        "2.  `def scan_for_pii(df_dict: Dict[str, pd.DataFrame], text_dict: Dict[str, str]) -> Dict[str, List[str]]:`: This function scans both DataFrames (column names and sample values from object-type columns) and raw text documents for occurrences of the defined PII patterns. It returns a dictionary `flags` indicating where PII was found.\n",
        "3.  `def sanitize_data_if_needed(df_dict: Dict[str, pd.DataFrame], flags: Dict[str, List[str]]) -> Dict[str, pd.DataFrame]:`: This function takes the DataFrames and the PII flags. If PII is detected, it creates a copy of the DataFrame and masks the identified PII. This includes renaming columns if their names match PII patterns and replacing actual PII values with `[MASKED]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yk6HHwVM2umB"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Guardrails implementation\n",
        "\n",
        "PII_PATTERNS = {\n",
        "    \"email\": re.compile(r\"[\\\\w\\\\.-]+@[\\\\w\\\\.-]+\", re.IGNORECASE),\n",
        "    \"phone\": re.compile(r\"\\\\b(?:\\\\+\\\\d{1,3}\\\\s?)?(?:\\\\(\\\\d{1,3}\\\\)|\\\\d{1,4})?[\\\\s.-]?\\\\d{2,4}[\\\\s.-]?\\\\d{2,4}[\\\\s.-]?\\\\d{2,4}\\\\b\")\n",
        "}\n",
        "\n",
        "def scan_for_pii(df_dict: Dict[str, pd.DataFrame], text_dict: Dict[str, str]) -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Scan DataFrames and text documents for PII patterns.\n",
        "    Returns a dict mapping 'df_columns'/'df_values'/'text' to lists of flagged items.\n",
        "    \"\"\"\n",
        "    flags = {\"df_columns\": [], \"df_values\": [], \"text\": []}\n",
        "    # Check column names\n",
        "    for fname, df in df_dict.items():\n",
        "        for col in df.columns:\n",
        "            if any(pattern.search(col) for pattern in PII_PATTERNS.values()):\n",
        "                flags[\"df_columns\"].append(f\"{fname}:{col}\")\n",
        "        # Check sample values (limit to first 5 rows for performance)\n",
        "        for col in df.select_dtypes(include=[object]).columns:\n",
        "            sample_vals = df[col].dropna().astype(str).head(5)\n",
        "            for val in sample_vals:\n",
        "                if any(pattern.search(val) for pattern in PII_PATTERNS.values()):\n",
        "                    flags[\"df_values\"].append(f\"{fname}:{col}:{val}\")\n",
        "    # Check raw text files\n",
        "    for fname, text in text_dict.items():\n",
        "        for pattern in PII_PATTERNS.values():\n",
        "            if pattern.search(text):\n",
        "                flags[\"text\"].append(fname)\n",
        "                break\n",
        "    return flags\n",
        "\n",
        "def sanitize_data_if_needed(df_dict: Dict[str, pd.DataFrame], flags: Dict[str, List[str]]) -> Dict[str, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Mask PII in DataFrames by replacing detected values with '[MASKED]'.\n",
        "    \"\"\"\n",
        "    masked = {}\n",
        "    for fname, df in df_dict.items():\n",
        "        df_copy = df.copy()\n",
        "        if any(fname in item for item in flags[\"df_columns\"] + flags[\"df_values\"]):\n",
        "            for col in df_copy.columns:\n",
        "                # Mask column names if flagged\n",
        "                if f\"{fname}:{col}\" in flags[\"df_columns\"]:\n",
        "                    df_copy.rename(columns={col: f\"{col}_MASKED\"}, inplace=True)\n",
        "                # Mask sample PII values in column\n",
        "                df_copy[col] = df_copy[col].astype(str).apply(\n",
        "                    lambda x: \"[MASKED]\" if any(p.search(x) for p in PII_PATTERNS.values()) else x\n",
        "                )\n",
        "        masked[fname] = df_copy\n",
        "    return masked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIfzLmDGqsqH"
      },
      "source": [
        "### Explanation of EDA agent implementation\n",
        "\n",
        "This cell defines the `run_eda` function, which performs Exploratory Data Analysis (EDA):\n",
        "\n",
        "1.  `def run_eda(df: pd.DataFrame, user_focus: Optional[str] = None) -> Dict[str, Any]:`: This function takes a pandas DataFrame and an optional `user_focus` string. It computes various descriptive statistics.\n",
        "2.  `eda_results[\"describe\"] = df.describe(include=\"all\").to_dict()`: Calculates descriptive statistics (count, mean, std, min, max, quartiles) for all columns in the DataFrame and stores them in a dictionary. `datetime_is_numeric` was commented out due to a potential error in the Colab environment.\n",
        "3.  `missing = df.isnull().sum().to_dict()`: Computes the count of missing values for each column.\n",
        "4.  `corr = numeric_df.corr().to_dict()`: If numeric columns exist, it calculates the pairwise correlation matrix between them.\n",
        "5.  `summary_lines`: Generates a textual summary of the DataFrame's shape, missing values, and whether numeric columns were analyzed, optionally including the `user_focus`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC5QcO0O29jd"
      },
      "outputs": [],
      "source": [
        "# Cell 5: EDA Agent implementation\n",
        "\n",
        "def run_eda(df: pd.DataFrame, user_focus: Optional[str] = None) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Compute basic exploratory statistics.\n",
        "    Args:\n",
        "        df: input DataFrame\n",
        "        user_focus: optional focus string (unused here but could guide selection)\n",
        "    Returns:\n",
        "        dict with 'describe', 'missing', 'correlation', 'summary'\n",
        "    \"\"\"\n",
        "    eda_results = {}\n",
        "    # Basic statistics\n",
        "    try:\n",
        "        # Removed datetime_is_numeric as it caused an error in this environment\n",
        "        eda_results[\"describe\"] = df.describe(include=\"all\").to_dict()\n",
        "    except Exception as e:\n",
        "        eda_results[\"describe\"] = {}\n",
        "        log(f\"EDA describe failed: {e}\", \"ERROR\")\n",
        "    # Missing values\n",
        "    missing = df.isnull().sum().to_dict()\n",
        "    eda_results[\"missing\"] = missing\n",
        "    # Correlation matrix (numeric only)\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    if not numeric_df.empty:\n",
        "        try:\n",
        "            corr = numeric_df.corr().to_dict()\n",
        "            eda_results[\"correlation\"] = corr\n",
        "        except Exception as e:\n",
        "            eda_results[\"correlation\"] = {}\n",
        "            log(f\"Correlation computation failed: {e}\", \"ERROR\")\n",
        "    else:\n",
        "        eda_results[\"correlation\"] = {}\n",
        "    # Brief summary text\n",
        "    summary_lines = [f\"DataFrame has {df.shape[0]} rows and {df.shape[1]} columns.\"]\n",
        "    summary_lines.append(f\"Missing values summary: {missing}\")\n",
        "    if numeric_df.shape[1] > 0:\n",
        "        summary_lines.append(\"Numeric columns summary available.\")\n",
        "    if user_focus:\n",
        "        summary_lines.append(f\"User focus: {user_focus}\")\n",
        "    eda_results[\"summary\"] = \"\\n\".join(summary_lines)\n",
        "    return eda_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oqzFo6zqU92"
      },
      "source": [
        "### Explanation of Data Science Agent\n",
        "\n",
        "This cell defines the `run_data_science` function, which performs deeper analytical tasks:\n",
        "\n",
        "1.  `from sklearn.linear_model import LinearRegression`, `from sklearn.model_selection import train_test_split`, `from sklearn.metrics import r2_score, mean_absolute_error`: Imports necessary libraries from scikit-learn for machine learning tasks.\n",
        "2.  `def run_data_science(df: pd.DataFrame, user_focus: Optional[str] = None) -> Dict[str, Any]:`: This function takes a DataFrame and `user_focus` and returns various analytical results.\n",
        "3.  **Correlation Insights**: It identifies and stores highly correlated numeric column pairs (correlation absolute value > 0.5).\n",
        "4.  **Grouped Aggregates**: For categorical columns, it calculates the mean of numeric columns grouped by each category, providing insights into group-wise differences.\n",
        "5.  **Time-series Trends**: It attempts to detect a date-like column, converts it to datetime objects, and then resamples the numeric data monthly to find trends over time.\n",
        "6.  **Simple Regression Model**: If there are at least two numeric columns, it attempts to build a simple linear regression model. It uses the last numeric column as the target variable and the preceding numeric columns as features. It splits the data into training and testing sets, trains a `LinearRegression` model, makes predictions, and reports the R-squared (`r2_score`) and Mean Absolute Error (`mean_absolute_error`). It handles `NaN` values by dropping rows with them before fitting the model.\n",
        "7.  **Summary Text**: It generates a textual summary of the key findings from the correlation analysis, grouped aggregates, time trends, and the regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zd-3G10p3GP0"
      },
      "outputs": [],
      "source": [
        "# Cell 6: Data Scientist Agent implementation\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "def run_data_science(df: pd.DataFrame, user_focus: Optional[str] = None) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Perform deeper analytical tasks on DataFrame.\n",
        "    Returns:\n",
        "        dict containing 'correlation_insights', 'group_aggregates', 'time_trends', 'model' (optional), 'summary'\n",
        "    \"\"\"\n",
        "    results: Dict[str, Any] = {}\n",
        "    # Correlation insights (top correlated pairs)\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    corr_pairs: List[Tuple[str, str, float]] = []\n",
        "    if not numeric_df.empty:\n",
        "        corr_mat = numeric_df.corr().abs()\n",
        "        for i, col1 in enumerate(numeric_df.columns):\n",
        "            for col2 in numeric_df.columns[i + 1:]:\n",
        "                corr_val = corr_mat.loc[col1, col2]\n",
        "                if not np.isnan(corr_val) and corr_val > 0.5:\n",
        "                    corr_pairs.append((col1, col2, corr_val))\n",
        "        results[\"correlation_insights\"] = sorted(corr_pairs, key=lambda x: -x[2])\n",
        "    else:\n",
        "        results[\"correlation_insights\"] = []\n",
        "    # Grouped aggregates for categorical columns\n",
        "    group_aggs = {}\n",
        "    cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "    for col in cat_cols:\n",
        "        # compute mean of numeric columns by categorical\n",
        "        aggs = df.groupby(col)[numeric_df.columns].mean().reset_index().head(5).to_dict(\"list\") if not numeric_df.empty else {}\n",
        "        group_aggs[col] = aggs\n",
        "    results[\"group_aggregates\"] = group_aggs\n",
        "    # Basic time-series trends if a date column exists\n",
        "    time_trends = {}\n",
        "    # Make a copy of df to avoid modifying the original DataFrame types for other nodes\n",
        "    df_for_time_analysis = df.copy()\n",
        "    for col in df_for_time_analysis.columns:\n",
        "        try:\n",
        "            df_for_time_analysis[col] = pd.to_datetime(df_for_time_analysis[col])\n",
        "            # if successful conversion, compute average of numeric columns over time\n",
        "            trend_df = df_for_time_analysis.dropna(subset=[col]).copy()\n",
        "            trend_df.set_index(col, inplace=True)\n",
        "            trend_df.sort_index(inplace=True)\n",
        "            resampled = trend_df[numeric_df.columns].resample('ME').mean().reset_index()  # monthly average (Month End)\n",
        "            time_trends[col] = resampled.to_dict(\"list\")\n",
        "            break  # only handle first date-like column\n",
        "        except Exception:\n",
        "            continue\n",
        "    results[\"time_trends\"] = time_trends\n",
        "    # Optional simple regression if clear target exists (last numeric column)\n",
        "    model_info = {}\n",
        "    if numeric_df.shape[1] >= 2:\n",
        "        # Drop rows with NaN values before fitting LinearRegression\n",
        "        numeric_df_cleaned = numeric_df.dropna()\n",
        "        if not numeric_df_cleaned.empty:\n",
        "            target_col = numeric_df_cleaned.columns[-1]\n",
        "            feature_cols = numeric_df_cleaned.columns[:-1]\n",
        "            X = numeric_df_cleaned[feature_cols]\n",
        "            y = numeric_df_cleaned[target_col]\n",
        "\n",
        "            # Ensure there are enough samples and features after dropping NaNs\n",
        "            if X.shape[0] > 0 and X.shape[1] > 0:\n",
        "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "                model = LinearRegression()\n",
        "                model.fit(X_train, y_train)\n",
        "                preds = model.predict(X_test)\n",
        "                model_info = {\n",
        "                    \"target\": target_col,\n",
        "                    \"features\": feature_cols.tolist(),\n",
        "                    \"r2\": r2_score(y_test, preds),\n",
        "                    \"mae\": mean_absolute_error(y_test, preds)\n",
        "                }\n",
        "    results[\"model\"] = model_info\n",
        "    # Summary text\n",
        "    summary_parts = []\n",
        "    if results[\"correlation_insights\"]:\n",
        "        pair_text = \", \".join([f\"{p[0]} vs {p[1]} (r={p[2]:.2f})\" for p in results[\"correlation_insights\"][:3]])\n",
        "        summary_parts.append(f\"Strong correlations found: {pair_text}.\")\n",
        "    if group_aggs:\n",
        "        summary_parts.append(f\"Grouped aggregates computed for: {', '.join(group_aggs.keys())}.\")\n",
        "    if time_trends:\n",
        "        summary_parts.append(\"Time trends computed for the first date-like column.\")\n",
        "    if model_info:\n",
        "        summary_parts.append(f\"Simple regression on {model_info['target']} (R²={model_info['r2']:.2f}).\")\n",
        "    results[\"summary\"] = \" \".join(summary_parts) or \"No significant patterns detected.\"\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI2os4U2p_j9"
      },
      "source": [
        "### Explanation of Plotting Agent\n",
        "\n",
        "This cell defines the `generate_plots` function, which creates various data visualizations using Matplotlib:\n",
        "\n",
        "1.  `import os`, `import uuid`, `import matplotlib.pyplot as plt`: Imports libraries for operating system interactions, generating unique IDs, and plotting.\n",
        "2.  `def generate_plots(df: pd.DataFrame, output_dir: str) -> List[Dict[str, str]]:`: This function takes a DataFrame and an output directory, then generates and saves several plot types.\n",
        "3.  **Distribution Plots**: For the first two numeric columns, it generates histograms (`df[col].plot.hist`) to show their distributions. These are saved as PNG files with unique names.\n",
        "4.  **Time-series Plot**: It checks if a date-like column exists. If found, it sorts the DataFrame by date and plots the first numeric column against time, showing trends. This plot is also saved.\n",
        "5.  **Categorical Plot**: If both categorical and numeric columns are present, it creates a bar plot showing the mean of the first numeric column grouped by the first categorical column. This helps visualize relationships between categorical and numerical data.\n",
        "6.  All generated plots are saved to the specified `output_dir` and their paths and captions are returned in a list of dictionaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2nBzE4N_Qx1"
      },
      "outputs": [],
      "source": [
        "# Cell 7: Plotting Agent implementation (modified for Matplotlib)\n",
        "\n",
        "import os\n",
        "import uuid\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_plots(df: pd.DataFrame, output_dir: str) -> List[Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Generate matplotlib charts for the DataFrame.\n",
        "    Args:\n",
        "        df: DataFrame to plot\n",
        "        output_dir: directory to save images\n",
        "    Returns:\n",
        "        list of dict with 'path' and 'caption'\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    plots: List[Dict[str, str]] = []\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "    # 1–2 distribution plots\n",
        "    for col in numeric_cols[:2]:\n",
        "        plt.figure()\n",
        "        df[col].plot.hist(bins=30)\n",
        "        plt.title(f\"Distribution of {col}\")\n",
        "        fname = f\"{uuid.uuid4().hex}_{col}_hist.png\"\n",
        "        fpath = os.path.join(output_dir, fname)\n",
        "        plt.savefig(fpath)\n",
        "        plt.close()\n",
        "        plots.append({\"path\": fpath, \"caption\": f\"Distribution of {col}\"})\n",
        "\n",
        "    # Time-series if a date column exists\n",
        "    date_col = None\n",
        "    for col in df.columns:\n",
        "        try:\n",
        "            pd.to_datetime(df[col])\n",
        "            date_col = col\n",
        "            break\n",
        "        except Exception:\n",
        "            continue\n",
        "    if date_col and numeric_cols:\n",
        "        plt.figure()\n",
        "        df_sorted = df.sort_values(by=date_col)\n",
        "        plt.plot(pd.to_datetime(df_sorted[date_col]), df_sorted[numeric_cols[0]])\n",
        "        plt.title(f\"{numeric_cols[0]} over time\")\n",
        "        fname = f\"{uuid.uuid4().hex}_{numeric_cols[0]}_trend.png\"\n",
        "        fpath = os.path.join(output_dir, fname)\n",
        "        plt.savefig(fpath)\n",
        "        plt.close()\n",
        "        plots.append({\"path\": fpath, \"caption\": f\"{numeric_cols[0]} over time\"})\n",
        "\n",
        "    # Category plot if categorical and numeric columns exist\n",
        "    cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "    if cat_cols and numeric_cols:\n",
        "        plt.figure()\n",
        "        df.groupby(cat_cols[0])[numeric_cols[0]].mean().plot.bar()\n",
        "        plt.title(f\"{numeric_cols[0]} by {cat_cols[0]}\")\n",
        "        fname = f\"{uuid.uuid4().hex}_{numeric_cols[0]}_by_{cat_cols[0]}.png\"\n",
        "        fpath = os.path.join(output_dir, fname)\n",
        "        plt.savefig(fpath)\n",
        "        plt.close()\n",
        "        plots.append({\"path\": fpath, \"caption\": f\"{numeric_cols[0]} by {cat_cols[0]}\"})\n",
        "\n",
        "    return plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS3VQKZrpo9e"
      },
      "source": [
        "### Explanation of Prompt and Context engineers\n",
        "\n",
        "This cell contains functions for prompt and context engineering, designed to condense complex analytical results into LLM-friendly formats:\n",
        "\n",
        "1.  `def compact_eda_context(eda_results: Dict[str, Any]) -> str:`: This function takes the detailed EDA results and extracts a brief textual summary, including the overall summary and a few key correlated columns. This makes the information concise for an LLM.\n",
        "2.  `def compact_science_context(science_results: Dict[str, Any]) -> str:`: Similar to `compact_eda_context`, this function extracts the `summary` field from the data science results for LLM consumption.\n",
        "3.  `def build_data_analyst_prompt(context: Dict[str, Any]) -> str:`: This function constructs a detailed prompt for the 'Data Analyst' LLM. It includes the user's goal, the compacted EDA and data science summaries, and a list of available plots (by their captions). The prompt instructs the LLM on its role and desired output format (headings and bullet points).\n",
        "4.  `def build_judge_prompt(context: Dict[str, Any]) -> str:`: This function builds a prompt for the 'LLM Judge' agent. It provides the user goal, the draft analyst narrative, and the same EDA/data science summaries and plot descriptions. The judge's role is to evaluate and potentially revise the analyst's narrative, with instructions to provide a revised narrative and an evaluation note."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-SgciZn3XUn"
      },
      "outputs": [],
      "source": [
        "# Cell 8: Prompt & Context Engineer\n",
        "\n",
        "def compact_eda_context(eda_results: Dict[str, Any]) -> str:\n",
        "    \"\"\"Condense EDA results into a short text snippet for LLMs.\"\"\"\n",
        "    desc = eda_results.get(\"summary\", \"\")\n",
        "    corr_insights = eda_results.get(\"correlation\", {})\n",
        "    corr_keys = list(corr_insights.keys())[:3]\n",
        "    corr_str = \", \".join(corr_keys)\n",
        "    return f\"{desc}\\nKey correlation columns: {corr_str}\"\n",
        "\n",
        "def compact_science_context(science_results: Dict[str, Any]) -> str:\n",
        "    \"\"\"Condense science results into a short text snippet.\"\"\"\n",
        "    return science_results.get(\"summary\", \"\")\n",
        "\n",
        "def build_data_analyst_prompt(context: Dict[str, Any]) -> str:\n",
        "    \"\"\"Create a prompt for the Data Analyst Agent.\"\"\"\n",
        "    goal = context.get(\"user_goal\", \"analyze the data\")\n",
        "    eda_summary = compact_eda_context(context.get(\"eda_results\", {}))\n",
        "    sci_summary = compact_science_context(context.get(\"science_results\", {}))\n",
        "    plots = context.get(\"plots\", [])\n",
        "    plot_descs = [p[\"caption\"] for p in plots]\n",
        "    return (\n",
        "        \"You are a data analyst. Your task is to provide a clear, non-technical narrative summarizing the findings.\\n\"\n",
        "        f\"User goal: {goal}\\n\"\n",
        "        \"EDA summary:\\n\"\n",
        "        f\"{eda_summary}\\n\"\n",
        "        \"Data science findings:\\n\"\n",
        "        f\"{sci_summary}\\n\"\n",
        "        \"Plots available:\\n\"\n",
        "        + \"\\n\".join(f\"- {desc}\" for desc in plot_descs) +\n",
        "        \"\\nStructure your response with headings (## Summary, ## Key Insights, ## Recommendations) and bullet points.\"\n",
        "    )\n",
        "\n",
        "def build_judge_prompt(context: Dict[str, Any]) -> str:\n",
        "    \"\"\"Create a prompt for the LLM Judge Agent.\"\"\"\n",
        "    goal = context.get(\"user_goal\", \"analyze the data\")\n",
        "    analyst_narrative = context.get(\"analyst_narrative\", \"\")\n",
        "    eda_summary = compact_eda_context(context.get(\"eda_results\", {}))\n",
        "    sci_summary = compact_science_context(context.get(\"science_results\", {}))\n",
        "    plots = context.get(\"plots\", [])\n",
        "    plot_descs = [p[\"caption\"] for p in plots]\n",
        "    return (\n",
        "        \"You are an expert reviewer of data analysis reports. Evaluate whether the narrative covers all important findings and \"\n",
        "        \"is coherent and complete. Identify gaps, contradictions, or missing links. If gaps exist, rewrite the narrative to fix them.\\n\"\n",
        "        f\"User goal: {goal}\\n\"\n",
        "        \"Analyst narrative:\\n\"\n",
        "        f\"{analyst_narrative}\\n\"\n",
        "        \"EDA summary:\\n\"\n",
        "        f\"{eda_summary}\\n\"\n",
        "        \"Data science findings:\\n\"\n",
        "        f\"{sci_summary}\\n\"\n",
        "        \"Plots available:\\n\"\n",
        "        + \"\\n\".join(f\"- {desc}\" for desc in plot_descs) +\n",
        "        \"\\nRespond with two parts:\\n\"\n",
        "        \"1. A revised narrative (with headings and bullet points).\\n\"\n",
        "        \"2. A brief evaluation note about what was improved or whether it was already complete.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPa-DbVApU5E"
      },
      "source": [
        "### Explanation of Gemini LLM wrapper\n",
        "\n",
        "This cell provides wrapper functions for interacting with the Google Gemini LLM:\n",
        "\n",
        "1.  `import google.generativeai as genai` and `from google.generativeai import GenerativeModel`: Imports the necessary Gemini API components.\n",
        "2.  `def init_gemini_model(model_name: str = \"gemini-2.5-pro\") -> GenerativeModel:`: Initializes a Gemini model. It calls `load_env_var` to get the `GOOGLE_API_KEY` and then configures and returns a `GenerativeModel` instance. The default model is `gemini-2.5-pro`.\n",
        "3.  `def call_gemini_analyst(prompt: str, model: GenerativeModel, max_retries: int = 2) -> str:`: This function sends a `prompt` to the Gemini model and retrieves its text response. It includes a retry mechanism (`max_retries`) to handle transient API errors, logging errors if attempts fail.\n",
        "4.  `def call_gemini_judge(prompt: str, model: GenerativeModel, max_retries: int = 2) -> str:`: Similar to `call_gemini_analyst`, this function calls the Gemini model specifically for the judge's role, also with retry logic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrKNW0Bt3hsU"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Gemini LLM wrappers\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.generativeai import GenerativeModel\n",
        "\n",
        "# Initialize Gemini models\n",
        "def init_gemini_model(model_name: str = \"gemini-2.5-pro\") -> GenerativeModel:\n",
        "    \"\"\"Initialize the Gemini model with the given name.\"\"\"\n",
        "    api_key = load_env_var(\"GOOGLE_API_KEY\")\n",
        "    genai.configure(api_key=api_key)\n",
        "    return genai.GenerativeModel(model_name)\n",
        "\n",
        "# Reusable call functions with retries\n",
        "def call_gemini_analyst(prompt: str, model: GenerativeModel, max_retries: int = 2) -> str:\n",
        "    \"\"\"Call Gemini for analyst narrative.\"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            log(f\"Gemini analyst call failed on attempt {attempt+1}: {e}\", \"ERROR\")\n",
        "    raise PipelineError(\"Gemini analyst call failed after retries.\")\n",
        "\n",
        "def call_gemini_judge(prompt: str, model: GenerativeModel, max_retries: int = 2) -> str:\n",
        "    \"\"\"Call Gemini for judge narrative.\"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            log(f\"Gemini judge call failed on attempt {attempt+1}: {e}\", \"ERROR\")\n",
        "    raise PipelineError(\"Gemini judge call failed after retries.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm8PMCxAo-FU"
      },
      "source": [
        "### Explanation of Data Analyst and LLM Judge\n",
        "\n",
        "This cell defines the wrapper functions for the Data Analyst and LLM-Judge agents:\n",
        "\n",
        "1.  `def run_data_analyst_agent(context: Dict[str, Any], model: GenerativeModel) -> str:`: This function orchestrates the Data Analyst agent. It first uses `build_data_analyst_prompt` to create a prompt based on the provided `context` (EDA results, science results, plots, user goal), then calls the Gemini model via `call_gemini_analyst` to generate the narrative. A truncated version of the draft narrative is printed for user review.\n",
        "2.  `def parse_judge_response(raw_response: str) -> Tuple[str, str]:`: This utility function is designed to parse the raw text response from the LLM Judge. It expects the response to be structured with a '1.' for the final narrative and '2.' for the evaluation notes, splitting the string accordingly.\n",
        "3.  `def run_llm_judge_agent(context: Dict[str, Any], model: GenerativeModel) -> Dict[str, str]:`: This function orchestrates the LLM Judge agent. It builds a judge-specific prompt using `build_judge_prompt`, sends it to the Gemini model via `call_gemini_judge`, and then parses the raw response into a final narrative and evaluation notes using `parse_judge_response`. Both are then printed and returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgUgPwaP3qGY"
      },
      "outputs": [],
      "source": [
        "# Cell 10: Data Analyst & LLM-Judge Agents (wrappers)\n",
        "\n",
        "def run_data_analyst_agent(context: Dict[str, Any], model: GenerativeModel) -> str:\n",
        "    \"\"\"Run Data Analyst Agent with Gemini.\"\"\"\n",
        "    prompt = build_data_analyst_prompt(context)\n",
        "    narrative = call_gemini_analyst(prompt, model)\n",
        "    return narrative\n",
        "\n",
        "def parse_judge_response(raw_response: str) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Parse the judge response into a final narrative and evaluation note.\n",
        "    We expect the model to separate parts (e.g. using numbered sections).\n",
        "    \"\"\"\n",
        "    parts = raw_response.split(\"2.\", 1)\n",
        "    final_narrative = parts[0].strip()\n",
        "    evaluation = parts[1].strip() if len(parts) > 1 else \"\"\n",
        "    return final_narrative, evaluation\n",
        "\n",
        "def run_llm_judge_agent(context: Dict[str, Any], model: GenerativeModel) -> Dict[str, str]:\n",
        "    \"\"\"Run LLM Judge Agent with Gemini.\"\"\"\n",
        "    prompt = build_judge_prompt(context)\n",
        "    raw = call_gemini_judge(prompt, model)\n",
        "    narrative, evaluation = parse_judge_response(raw)\n",
        "    return {\"final_narrative\": narrative, \"evaluation_notes\": evaluation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNN2ZyIHokle"
      },
      "source": [
        "### Explanation of Report generation agent\n",
        "\n",
        "This cell defines the `generate_word_report` function, which creates a Word document from the analysis results:\n",
        "\n",
        "1.  `def generate_word_report(final_narrative: str, plots: List[Dict[str, str]], output_path: str = \"/content/report\") -> str:`: This function takes the final narrative, a list of plot details, and an output path. It uses the `python-docx` library to create a `.docx` file.\n",
        "2.  `os.makedirs(output_path, exist_ok=True)`: Ensures that the output directory for the report exists.\n",
        "3.  `doc = Document()`: Initializes a new Word document.\n",
        "4.  **Content Population**: It adds a main title, generation timestamp, and then iterates through the `final_narrative` (which is expected to contain Markdown-like headings and bullet points) to format it appropriately in the Word document.\n",
        "5.  **Plot Embedding**: If `plots` are provided, it adds a 'Visualizations' heading and then inserts each plot as an image with its corresponding caption into the document.\n",
        "6.  `doc.save(report_file)`: Saves the generated Word document to a uniquely named file within the specified output path and returns the absolute path to the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDKIst6A3wLD"
      },
      "outputs": [],
      "source": [
        "# Cell 11: Report Generator Agent\n",
        "\n",
        "def generate_word_report(final_narrative: str, plots: List[Dict[str, str]], output_path: str = \"/content/report\") -> str:\n",
        "    \"\"\"\n",
        "    Generate a Word document containing the final narrative and embed the plots.\n",
        "    Args:\n",
        "        final_narrative: the narrative to include in the document (Markdown-like headings allowed).\n",
        "        plots: list of dicts with 'path' and 'caption'\n",
        "        output_path: directory to save the docx file\n",
        "    Returns:\n",
        "        absolute path to the generated docx\n",
        "    \"\"\"\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "    doc = Document()\n",
        "    # Title page\n",
        "    doc.add_heading(\"Data Analysis Report\", level=1)\n",
        "    doc.add_paragraph(f\"Generated on {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    doc.add_paragraph(\"\\n\")\n",
        "    # Split narrative by lines to handle headings and bullet points\n",
        "    for line in final_narrative.splitlines():\n",
        "        if line.startswith(\"# \"):\n",
        "            doc.add_heading(line.replace(\"# \", \"\"), level=1)\n",
        "        elif line.startswith(\"## \"):\n",
        "            doc.add_heading(line.replace(\"## \", \"\"), level=2)\n",
        "        elif line.startswith(\"* \") or line.startswith(\"- \"):\n",
        "            doc.add_paragraph(line.replace(\"* \", \"\").replace(\"- \", \"\"), style='List Bullet')\n",
        "        else:\n",
        "            doc.add_paragraph(line)\n",
        "    # Insert plots\n",
        "    if plots:\n",
        "        doc.add_heading(\"Visualizations\", level=2)\n",
        "        for idx, plot in enumerate(plots, 1):\n",
        "            doc.add_paragraph(f\"Figure {idx}: {plot['caption']}\", style='Caption')\n",
        "            doc.add_picture(plot[\"path\"], width=Inches(5))\n",
        "    report_file = os.path.join(output_path, f\"final_report_{uuid.uuid4().hex}.docx\")\n",
        "    doc.save(report_file)\n",
        "    return report_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWqGihQqn7L3"
      },
      "source": [
        "### Explanation of LangGraph orchestration & Human‑in‑Loop\n",
        "\n",
        "This cell implements the main orchestration logic using LangGraph, including the `PipelineState` and node definitions:\n",
        "\n",
        "1.  `from dataclasses import dataclass, field`, `from typing import List, Dict`, `from langgraph.graph import StateGraph`: Imports necessary components for data classes, type hinting, and LangGraph.\n",
        "2.  `@dataclass class PipelineState:`: Defines a `PipelineState` class using `dataclass` to hold all relevant data throughout the pipeline. This includes raw files, dataframes, documents, results from EDA, data science, plots, narratives, user inputs, and guardrail flags.\n",
        "3.  **Node Functions (`node_ingestion`, `node_guardrails_input`, etc.)**: Each of these functions represents a distinct step or agent in the data analysis pipeline. They take the current `PipelineState`, perform their specific task (e.g., loading files, running EDA, generating plots), and update the state.\n",
        "    *   `node_ingestion`: Loads tabular and textual files into dataframes and documents.\n",
        "    *   `node_guardrails_input`: Scans for PII and sanitizes data if found.\n",
        "    *   `node_eda`: Runs exploratory data analysis.\n",
        "    *   `node_user_checkpoint_1`: A human-in-the-loop checkpoint to gather user focus after EDA.\n",
        "    *   `node_data_science`: Performs advanced data science analysis.\n",
        "    *   `node_plotting`: Generates visualizations.\n",
        "    *   `node_data_analyst`: Uses an LLM to generate an initial narrative.\n",
        "    *   `node_llm_judge`: Uses an LLM to review and refine the narrative.\n",
        "    *   `node_user_checkpoint_2`: Another human-in-the-loop checkpoint for final narrative review/modification.\n",
        "    *   `node_guardrails_output`: Scans the final narrative for PII before report generation.\n",
        "    *   `node_report_generation`: Creates the final Word report.\n",
        "4.  **`build_pipeline_graph(model: GenerativeModel) -> StateGraph:`**: This function constructs the LangGraph graph:\n",
        "    *   It initializes a `StateGraph` with `PipelineState`.\n",
        "    *   It adds each node function (`ingestion`, `guardrails_input`, etc.) to the graph.\n",
        "    *   It defines the sequential `edges` between these nodes, establishing the workflow of the pipeline.\n",
        "    *   It sets the `entry_point` for the graph to `ingestion`.\n",
        "5.  **`run_pipeline(user_goal: str, uploaded_files: Dict[str, Any]) -> PipelineState:`**: This is the main entry point to execute the entire pipeline. It initializes the Gemini model, creates an initial `PipelineState` with the user's goal and uploaded files, builds the graph, compiles it (`app = graph.compile()`), and then invokes the compiled graph with the initial state. The final `PipelineState` is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rvf-c0kv32-C"
      },
      "outputs": [],
      "source": [
        "# Cell 12: Orchestrator (LangGraph)\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict\n",
        "\n",
        "# Corrected import for Graph\n",
        "from langgraph.graph import StateGraph\n",
        "\n",
        "@dataclass\n",
        "class PipelineState:\n",
        "    raw_files: Dict[str, Any] = field(default_factory=dict)\n",
        "    dataframes: Dict[str, pd.DataFrame] = field(default_factory=dict)\n",
        "    documents: Dict[str, str] = field(default_factory=dict)\n",
        "    eda_results: Dict[str, Any] = field(default_factory=dict)\n",
        "    science_results: Dict[str, Any] = field(default_factory=dict)\n",
        "    plots: List[Dict[str, str]] = field(default_factory=list)\n",
        "    analyst_narrative: str = \"\"\n",
        "    judge_narrative: str = \"\"\n",
        "    evaluation_notes: str = \"\"\n",
        "    user_focus: Optional[str] = None\n",
        "    user_goal: str = \"\"\n",
        "    guardrails_flags: Dict[str, List[str]] = field(default_factory=dict)\n",
        "    final_report_path: Optional[str] = None\n",
        "\n",
        "# Define node functions\n",
        "def node_ingestion(state: PipelineState) -> PipelineState:\n",
        "    log(\"Node: Ingestion started.\")\n",
        "    # Data is now expected to be in state.raw_files\n",
        "    state.dataframes = load_tabular_files(state.raw_files)\n",
        "    state.documents = load_textual_files(state.raw_files)\n",
        "    return state\n",
        "\n",
        "def node_guardrails_input(state: PipelineState) -> PipelineState:\n",
        "    log(\"Node: Guardrails input check.\")\n",
        "    flags = scan_for_pii(state.dataframes, state.documents)\n",
        "    state.guardrails_flags = flags\n",
        "    if any(flags.values()):\n",
        "        log(f\"PII detected: {flags}\", \"WARNING\")\n",
        "        state.dataframes = sanitize_data_if_needed(state.dataframes, flags)\n",
        "    return state\n",
        "\n",
        "def node_eda(state: PipelineState) -> PipelineState:\n",
        "    log(\"Node: EDA started.\")\n",
        "    # Run on first dataframe only (extend as needed)\n",
        "    if not state.dataframes:\n",
        "        raise PipelineError(\"No DataFrames loaded for EDA.\")\n",
        "    df_name = list(state.dataframes.keys())[0]\n",
        "    df = state.dataframes[df_name]\n",
        "    state.eda_results = run_eda(df, state.user_focus)\n",
        "    # Show summary to user\n",
        "    print(\"EDA Summary:\")\n",
        "    print(state.eda_results[\"summary\"])\n",
        "    return state\n",
        "\n",
        "def node_user_checkpoint_1(state: PipelineState) -> PipelineState:\n",
        "    log(\"Node: Human checkpoint after EDA.\")\n",
        "    focus = input(\"Enter any specific focus (press Enter to continue): \").strip()\n",
        "    state.user_focus = focus or None\n",
        "    return state\n",
        "\n",
        "def node_data_science(state: PipelineState) -> PipelineState:\n",
        "    log(\"Node: Data Science analysis started.\")\n",
        "    df_name = list(state.dataframes.keys())[0]\n",
        "    df = state.dataframes[df_name]\n",
        "    state.science_results = run_data_science(df, state.user_focus)\n",
        "    print(\"Data Science Summary:\")\n",
        "    print(state.science_results[\"summary\"])\n",
        "    return state\n",
        "\n",
        "def node_plotting(state: PipelineState) -> PipelineState:\n",
        "    log(\"Node: Plotting started.\")\n",
        "    df_name = list(state.dataframes.keys())[0]\n",
        "    df = state.dataframes[df_name]\n",
        "    output_dir = \"/content/plots\"\n",
        "    state.plots = generate_plots(df, output_dir)\n",
        "    return state\n",
        "\n",
        "def node_data_analyst(state: PipelineState, model: GenerativeModel) -> PipelineState:\n",
        "    log(\"Node: Data Analyst LLM started.\")\n",
        "    context = {\n",
        "        \"user_goal\": state.user_goal,\n",
        "        \"eda_results\": state.eda_results,\n",
        "        \"science_results\": state.science_results,\n",
        "        \"plots\": state.plots\n",
        "    }\n",
        "    narrative = run_data_analyst_agent(context, model)\n",
        "    state.analyst_narrative = narrative\n",
        "    print(\"Analyst Narrative (draft):\")\n",
        "    print(narrative[:500])\n",
        "    return state\n",
        "\n",
        "def node_llm_judge(state: PipelineState, model: GenerativeModel) -> PipelineState:\n",
        "    log(\"Node: LLM Judge started.\")\n",
        "    context = {\n",
        "        \"user_goal\": state.user_goal,\n",
        "        \"analyst_narrative\": state.analyst_narrative,\n",
        "        \"eda_results\": state.eda_results,\n",
        "        \"science_results\": state.science_results,\n",
        "        \"plots\": state.plots\n",
        "    }\n",
        "    judge_out = run_llm_judge_agent(context, model)\n",
        "    state.judge_narrative = judge_out[\"final_narrative\"]\n",
        "    state.evaluation_notes = judge_out[\"evaluation_notes\"]\n",
        "    print(\"Judge Narrative:\")\n",
        "    print(state.judge_narrative[:500])\n",
        "    print(\"Evaluation Notes:\")\n",
        "    print(state.evaluation_notes)\n",
        "    return state\n",
        "\n",
        "def node_user_checkpoint_2(state: PipelineState) -> PipelineState:\n",
        "    log(\"Node: Human checkpoint before final report.\")\n",
        "    print(\"Draft final narrative:\")\n",
        "    print(state.judge_narrative[:500])\n",
        "    extra = input(\"Any extra requests or modifications (press Enter to continue): \").strip()\n",
        "    if extra:\n",
        "        state.analyst_narrative += \"\\nAdditional user request: \" + extra\n",
        "    return state\n",
        "\n",
        "def node_guardrails_output(state: PipelineState) -> PipelineState:\n",
        "    log(\"Node: Guardrails output check.\")\n",
        "    # Re-run PII check on narrative\n",
        "    flags_out = {\"text\": []}\n",
        "    if PII_PATTERNS[\"email\"].search(state.judge_narrative) or PII_PATTERNS[\"phone\"].search(state.judge_narrative):\n",
        "        flags_out[\"text\"].append(\"narrative\")\n",
        "    if flags_out[\"text\"]:\n",
        "        log(\"Warning: PII-like content detected in narrative.\", \"WARNING\")\n",
        "        # mask PII-like content\n",
        "        state.judge_narrative = PII_PATTERNS[\"email\"].sub(\"[MASKED_EMAIL]\", state.judge_narrative)\n",
        "        state.judge_narrative = PII_PATTERNS[\"phone\"].sub(\"[MASKED_PHONE]\", state.judge_narrative)\n",
        "    return state\n",
        "\n",
        "def node_report_generation(state: PipelineState) -> PipelineState:\n",
        "    log(\"Node: Report generation started.\")\n",
        "    output_dir = \"/content/report\"\n",
        "    final_path = generate_word_report(state.judge_narrative, state.plots, output_dir)\n",
        "    state.final_report_path = final_path\n",
        "    return state\n",
        "\n",
        "# Construct LangGraph graph\n",
        "def build_pipeline_graph(model: GenerativeModel) -> StateGraph:\n",
        "    graph = StateGraph(PipelineState)\n",
        "    graph.add_node(\"ingestion\", node_ingestion)\n",
        "    graph.add_node(\"guardrails_input\", node_guardrails_input)\n",
        "    graph.add_node(\"eda\", node_eda)\n",
        "    graph.add_node(\"human_1\", node_user_checkpoint_1)\n",
        "    graph.add_node(\"data_science\", node_data_science)\n",
        "    graph.add_node(\"plotting\", node_plotting)\n",
        "    graph.add_node(\"analyst\", lambda state: node_data_analyst(state, model))\n",
        "    graph.add_node(\"judge\", lambda state: node_llm_judge(state, model))\n",
        "    graph.add_node(\"human_2\", node_user_checkpoint_2)\n",
        "    graph.add_node(\"guardrails_output\", node_guardrails_output)\n",
        "    graph.add_node(\"report\", node_report_generation)\n",
        "\n",
        "    # Edges\n",
        "    graph.set_entry_point(\"ingestion\")\n",
        "    graph.add_edge(\"ingestion\", \"guardrails_input\")\n",
        "    graph.add_edge(\"guardrails_input\", \"eda\")\n",
        "    graph.add_edge(\"eda\", \"human_1\")\n",
        "    graph.add_edge(\"human_1\", \"data_science\")\n",
        "    graph.add_edge(\"data_science\", \"plotting\")\n",
        "    graph.add_edge(\"plotting\", \"analyst\")\n",
        "    graph.add_edge(\"analyst\", \"judge\")\n",
        "    graph.add_edge(\"judge\", \"human_2\")\n",
        "    graph.add_edge(\"human_2\", \"guardrails_output\")\n",
        "    graph.add_edge(\"guardrails_output\", \"report\")\n",
        "\n",
        "    return graph\n",
        "\n",
        "def run_pipeline(user_goal: str, uploaded_files: Dict[str, Any]) -> PipelineState:\n",
        "    \"\"\"Entry point to run the pipeline end-to-end.\"\"\"\n",
        "    model = init_gemini_model()\n",
        "    # Initialize state with raw_files\n",
        "    state = PipelineState(user_goal=user_goal, raw_files=uploaded_files)\n",
        "    graph = build_pipeline_graph(model)\n",
        "    # Compile the graph before running\n",
        "    app = graph.compile()\n",
        "    # Invoke the compiled graph, passing the initial state\n",
        "    result_state = app.invoke(input=state, config={\"recursion_limit\": 50})\n",
        "    return result_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Hwk1hDnfe0"
      },
      "source": [
        "### Explanation of Langgraph mermaid diagram\n",
        "\n",
        "This cell is responsible for visualizing the LangGraph pipeline and ensuring necessary installations:\n",
        "\n",
        "1.  `!pip install -q langgraph`: Ensures that the `langgraph` library is installed. The output confirms successful installation.\n",
        "2.  `!sudo apt-get install -y graphviz`: Installs `graphviz`, a graph visualization software. This is required by `langgraph` to render the pipeline graph. The output indicates `graphviz` is already installed and up-to-date.\n",
        "3.  `model = init_gemini_model()`: Initializes the Gemini model using the function defined earlier.\n",
        "4.  `graph = build_pipeline_graph(model)`: Constructs the LangGraph graph using the initialized Gemini model.\n",
        "5.  `app = graph.compile()`: Compiles the constructed graph. Compilation optimizes the graph for execution.\n",
        "6.  `mermaid_png_data = app.get_graph().draw_mermaid_png()`: This line is crucial for visualization. It uses the `draw_mermaid_png()` method of the compiled graph to generate a PNG image representing the pipeline structure in Mermaid syntax. This image data is returned as bytes.\n",
        "7.  **Saving and Displaying the Image**: The code then creates a directory `/content/mermaid_charts`, generates a unique filename, writes the `mermaid_png_data` to a file, and finally uses `display(Image(filename=image_path))` to show the generated PNG image directly within the Colab output. This allows the user to visually understand the flow of the LangGraph pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1EDUqObubvo2",
        "outputId": "98cc7bb1-3273-438d-fffc-850716b0ffb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 57 not upgraded.\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import langgraph\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "# Ensure langgraph is installed\n",
        "!pip install -q langgraph\n",
        "\n",
        "!sudo apt-get install -y graphviz  # Only needed once if not already installed\n",
        "\n",
        "model = init_gemini_model()          # or whatever model initialiser you use\n",
        "graph = build_pipeline_graph(model)  # returns a StateGraph\n",
        "\n",
        "# Compile the graph before visualizing\n",
        "app = graph.compile()\n",
        "\n",
        "# Render the Mermaid PNG and get its data\n",
        "mermaid_png_data = app.get_graph().draw_mermaid_png()\n",
        "\n",
        "# Save the PNG data to a persistent file and then display it\n",
        "persistent_dir = \"/content/mermaid_charts\"\n",
        "os.makedirs(persistent_dir, exist_ok=True)\n",
        "image_filename = f\"graph_{uuid.uuid4().hex}.png\"\n",
        "image_path = os.path.join(persistent_dir, image_filename)\n",
        "\n",
        "with open(image_path, \"wb\") as f:\n",
        "    f.write(mermaid_png_data)\n",
        "\n",
        "display(Image(filename=image_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9d5emvnnJWp"
      },
      "source": [
        "### Explanation of demo run\n",
        "\n",
        "This cell demonstrates a full run of the data analysis pipeline, handling data loading from different sources:\n",
        "\n",
        "1.  `import kagglehub`, `from google.colab import files`, `import os`, `from io import BytesIO`: Imports necessary modules for Kaggle data access, Colab file uploads, OS interactions, and byte stream handling.\n",
        "2.  `user_goal = \"Perform a comprehensive analysis of Netflix shows data to identify trends and patterns.\"`: Defines the user's overall objective for the analysis.\n",
        "3.  `file_source_choice = 'kaggle'`: This variable determines how the input data is obtained. It's set to `'kaggle'` by default.\n",
        "4.  **Data Source Logic**:\n",
        "    *   If `file_source_choice == 'kaggle'`: It attempts to download the `creditcardfraud` dataset from Kaggle using `kagglehub.dataset_download`. It then reads `creditcard.csv` into a pandas DataFrame, converts it to bytes using `BytesIO`, and stores it in `final_data_for_pipeline`.\n",
        "    *   If `file_source_choice == 'upload'`: (Not executed in this run due to `kaggle` choice) It would prompt the user to upload files using `files.upload()`.\n",
        "    *   If `file_source_choice == 'dummy'` or if Kaggle/upload fails: It creates a simple dummy pandas DataFrame with `date`, `sales`, and `category` columns, converts it to bytes, and uses it as input.\n",
        "    *   In this specific execution, the Kaggle dataset was successfully downloaded and processed. The logs show \"Using Kaggle dataset: /kaggle/input/creditcardfraud/creditcard.csv\".\n",
        "5.  `final_state = run_pipeline(user_goal, final_data_for_pipeline)`: This is the core step where the entire LangGraph pipeline (defined in the previous cells) is executed. It passes the `user_goal` and the loaded `final_data_for_pipeline` to the `run_pipeline` function.\n",
        "6.  **Output Printing**: After the pipeline completes, it prints key outputs from the `final_state`:\n",
        "    *   The `final_state['judge_narrative']` (the refined analysis report from the LLM Judge).\n",
        "    *   The `final_state['evaluation_notes']` (the judge's feedback on the initial analyst narrative).\n",
        "    *   A list of generated plots (captions and file paths).\n",
        "    *   The path to the generated Word report (`final_state['final_report_path']`).\n",
        "\n",
        "The output shows the progress through each node of the pipeline, including summaries from EDA and Data Science, the draft analyst narrative, the judge's revised narrative and evaluation, and the details of the generated plots and report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6r_BtBX4n5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf3a139-2a9e-4483-eeab-193018a8dcfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'creditcardfraud' dataset.\n",
            "[2025-11-30 15:50:13] [INFO] Using Kaggle dataset: /kaggle/input/creditcardfraud/creditcard.csv\n",
            "[2025-11-30 15:50:32] [INFO] Node: Ingestion started.\n",
            "[2025-11-30 15:50:35] [INFO] Node: Guardrails input check.\n",
            "[2025-11-30 15:50:35] [INFO] Node: EDA started.\n",
            "EDA Summary:\n",
            "DataFrame has 284807 rows and 31 columns.\n",
            "Missing values summary: {'Time': 0, 'V1': 0, 'V2': 0, 'V3': 0, 'V4': 0, 'V5': 0, 'V6': 0, 'V7': 0, 'V8': 0, 'V9': 0, 'V10': 0, 'V11': 0, 'V12': 0, 'V13': 0, 'V14': 0, 'V15': 0, 'V16': 0, 'V17': 0, 'V18': 0, 'V19': 0, 'V20': 0, 'V21': 0, 'V22': 0, 'V23': 0, 'V24': 0, 'V25': 0, 'V26': 0, 'V27': 0, 'V28': 0, 'Amount': 0, 'Class': 0}\n",
            "Numeric columns summary available.\n",
            "[2025-11-30 15:50:37] [INFO] Node: Human checkpoint after EDA.\n",
            "[2025-11-30 15:56:21] [INFO] Node: Data Science analysis started.\n",
            "Data Science Summary:\n",
            "Strong correlations found: V2 vs Amount (r=0.53). Simple regression on Class (R²=0.52).\n",
            "[2025-11-30 15:56:30] [INFO] Node: Plotting started.\n",
            "[2025-11-30 15:56:31] [INFO] Node: Data Analyst LLM started.\n",
            "Analyst Narrative (draft):\n",
            "Of course. Here is a clear, non-technical summary of the findings based on the provided data.\n",
            "\n",
            "***\n",
            "\n",
            "### **Important Note on the Data Provided**\n",
            "\n",
            "The summary you've shared (with columns like 'V1', 'V2', 'Amount', 'Class') does not appear to be about Netflix shows. This type of data, with anonymized \"V\" columns, is characteristic of transactional or event data, such as credit card transactions, where sensitive information has been hidden for privacy.\n",
            "\n",
            "Therefore, the following analysis is based on \n",
            "[2025-11-30 15:57:01] [INFO] Node: LLM Judge started.\n",
            "Judge Narrative:\n",
            "Here is the revised narrative and the evaluation note.\n",
            "\n",
            "***\n",
            "\n",
            "### **1. Revised Narrative**\n",
            "\n",
            "### **Important Note on the Data Provided**\n",
            "\n",
            "The analysis is based on a dataset with anonymized columns ('V1', 'V2', etc.), characteristic of transactional or event data, not Netflix shows. The findings below describe patterns in these transactions, not trends in media content.\n",
            "\n",
            "---\n",
            "\n",
            "### **Analysis of Transaction Patterns**\n",
            "\n",
            "We analyzed a high-quality dataset of over 284,000 transactions with no missing da\n",
            "Evaluation Notes:\n",
            "Evaluation Note**\n",
            "\n",
            "The original narrative was well-structured and correctly identified the mismatch between the user's goal (Netflix) and the provided data (transactions). However, it was incomplete.\n",
            "\n",
            "**Improvements in the Revised Narrative:**\n",
            "\n",
            "*   **Completeness:** The original narrative completely omitted any mention of the 'V1' variable, despite the technical summary identifying it as a \"Key correlation column\" with an available distribution plot. The revised narrative integrates the findings for 'V1', presenting a more complete picture of the key drivers in the data.\n",
            "*   **Specificity and Cohesion:** The revised version adds the specific correlation value (r = 0.53) for 'V2' vs. 'Amount' and clarifies the meaning of the 52% model performance (R²). It also creates a more cohesive story by framing the findings around three primary drivers (key factors, value, and timing).\n",
            "*   **Actionable Recommendations:** The recommendations were updated to include investigating 'V1' alongside 'V2', making them more comprehensive and directly tied to all key findings.\n",
            "[2025-11-30 15:57:31] [INFO] Node: Human checkpoint before final report.\n",
            "Draft final narrative:\n",
            "Here is the revised narrative and the evaluation note.\n",
            "\n",
            "***\n",
            "\n",
            "### **1. Revised Narrative**\n",
            "\n",
            "### **Important Note on the Data Provided**\n",
            "\n",
            "The analysis is based on a dataset with anonymized columns ('V1', 'V2', etc.), characteristic of transactional or event data, not Netflix shows. The findings below describe patterns in these transactions, not trends in media content.\n",
            "\n",
            "---\n",
            "\n",
            "### **Analysis of Transaction Patterns**\n",
            "\n",
            "We analyzed a high-quality dataset of over 284,000 transactions with no missing da\n",
            "Any extra requests or modifications (press Enter to continue): Continue \n",
            "[2025-11-30 15:59:17] [INFO] Node: Guardrails output check.\n",
            "[2025-11-30 15:59:17] [INFO] Node: Report generation started.\n",
            "\n",
            "Final narrative:\n",
            "Here is the revised narrative and the evaluation note.\n",
            "\n",
            "***\n",
            "\n",
            "### **1. Revised Narrative**\n",
            "\n",
            "### **Important Note on the Data Provided**\n",
            "\n",
            "The analysis is based on a dataset with anonymized columns ('V1', 'V2', etc.), characteristic of transactional or event data, not Netflix shows. The findings below describe patterns in these transactions, not trends in media content.\n",
            "\n",
            "---\n",
            "\n",
            "### **Analysis of Transaction Patterns**\n",
            "\n",
            "We analyzed a high-quality dataset of over 284,000 transactions with no missing data. Our analysis identified three primary drivers of transaction behavior: the transaction's inherent characteristics (represented by factors 'V1' and 'V2'), its monetary value ('Amount'), and its timing ('Time').\n",
            "\n",
            "### **Key Findings**\n",
            "\n",
            "*   **Two Factors Drive Transaction Profiles:** Two anonymized factors, 'V1' and 'V2', were identified as the most influential variables. The distribution of 'V1' suggests it represents a primary, distinct characteristic of the transactions. Separately, 'V2' has \n",
            "\n",
            "Evaluation notes:\n",
            "Evaluation Note**\n",
            "\n",
            "The original narrative was well-structured and correctly identified the mismatch between the user's goal (Netflix) and the provided data (transactions). However, it was incomplete.\n",
            "\n",
            "**Improvements in the Revised Narrative:**\n",
            "\n",
            "*   **Completeness:** The original narrative completely omitted any mention of the 'V1' variable, despite the technical summary identifying it as a \"Key correlation column\" with an available distribution plot. The revised narrative integrates the findings for 'V1', presenting a more complete picture of the key drivers in the data.\n",
            "*   **Specificity and Cohesion:** The revised version adds the specific correlation value (r = 0.53) for 'V2' vs. 'Amount' and clarifies the meaning of the 52% model performance (R²). It also creates a more cohesive story by framing the findings around three primary drivers (key factors, value, and timing).\n",
            "*   **Actionable Recommendations:** The recommendations were updated to include investigating 'V1' alongside 'V2', making them more comprehensive and directly tied to all key findings.\n",
            "\n",
            "Plots:\n",
            "- Distribution of Time: /content/plots/bfc42d69931d4631ba5f184c2dea0737_Time_hist.png\n",
            "- Distribution of V1: /content/plots/552c1825b1e846c4be35dc049240533b_V1_hist.png\n",
            "- Time over time: /content/plots/5a68aaa3ee6146a097a192c379fdf365_Time_trend.png\n",
            "\n",
            "Word report saved to: /content/report/final_report_f34fc2bd5aa949dfbd42efd455b4212d.docx\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "from google.colab import files\n",
        "import os\n",
        "from io import BytesIO\n",
        "\n",
        "# User goal\n",
        "user_goal = \"Perform a comprehensive analysis of Netflix shows data to identify trends and patterns.\"\n",
        "\n",
        "# --- Choose Data Source ---\n",
        "# Set this to 'upload' to prompt for file upload, or 'kaggle' to use the default Kaggle dataset.\n",
        "# You can also set it to 'dummy' for a simple generated dataset if no file is uploaded.\n",
        "file_source_choice = 'kaggle' # @param ['upload', 'kaggle', 'dummy']\n",
        "\n",
        "final_data_for_pipeline = {}\n",
        "\n",
        "if file_source_choice == 'kaggle':\n",
        "    # Use kagglehub to download the dataset\n",
        "    path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "    csv_file_name = 'creditcard.csv'\n",
        "    full_kaggle_path = os.path.join(path, csv_file_name)\n",
        "\n",
        "    if os.path.exists(full_kaggle_path):\n",
        "        log(f\"Using Kaggle dataset: {full_kaggle_path}\", \"INFO\")\n",
        "        df_kaggle = pd.read_csv(full_kaggle_path)\n",
        "        kaggle_buf = BytesIO()\n",
        "        df_kaggle.to_csv(kaggle_buf, index=False)\n",
        "        kaggle_buf.seek(0)\n",
        "        final_data_for_pipeline = {csv_file_name: kaggle_buf.getvalue()}\n",
        "    else:\n",
        "        log(\"Kaggle dataset not found. Falling back to dummy data.\", \"WARNING\")\n",
        "        file_source_choice = 'dummy' # Force dummy if Kaggle not found\n",
        "\n",
        "if file_source_choice == 'upload':\n",
        "    log(\"Please upload your files for analysis.\", \"INFO\")\n",
        "    uploaded_files = files.upload()\n",
        "    if uploaded_files:\n",
        "        final_data_for_pipeline = uploaded_files\n",
        "    else:\n",
        "        log(\"No files uploaded. Falling back to dummy data.\", \"WARNING\")\n",
        "        file_source_choice = 'dummy' # Force dummy if no files uploaded\n",
        "\n",
        "if file_source_choice == 'dummy' or not final_data_for_pipeline:\n",
        "    log(\"Using a dummy dataset for demo.\", \"INFO\")\n",
        "    demo_df = pd.DataFrame({\n",
        "        \"date\": pd.date_range(start=\"2025-01-01\", periods=100, freq=\"D\"),\n",
        "        \"sales\": np.random.randint(100, 1000, size=100),\n",
        "        \"category\": np.random.choice([\"A\", \"B\", \"C\"], size=100)\n",
        "    })\n",
        "    demo_buf = BytesIO()\n",
        "    demo_df.to_csv(demo_buf, index=False)\n",
        "    demo_buf.seek(0)\n",
        "    final_data_for_pipeline = {\"demo.csv\": demo_buf.getvalue()}\n",
        "\n",
        "# Run the pipeline with the selected data source\n",
        "final_state = run_pipeline(user_goal, final_data_for_pipeline)\n",
        "\n",
        "# Print final outputs\n",
        "print(\"\\nFinal narrative:\")\n",
        "print(final_state['judge_narrative'][:1000])\n",
        "print(\"\\nEvaluation notes:\")\n",
        "print(final_state['evaluation_notes'])\n",
        "print(\"\\nPlots:\")\n",
        "if final_state['plots']:\n",
        "    for p in final_state['plots']:\n",
        "        print(f\"- {p['caption']}: {p['path']}\")\n",
        "else:\n",
        "    print(\"No plots generated.\")\n",
        "print(\"\\nWord report saved to:\", final_state['final_report_path'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORFueiBMiQpixy6Fnh1gpA"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}